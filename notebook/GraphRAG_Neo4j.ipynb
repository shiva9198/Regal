{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "%pip install neo4j pymilvus numpy scipy langchain langchain-core langchain-openai tqdm"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from neo4j import GraphDatabase\n",
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from pymilvus import MilvusClient\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from tqdm import tqdm\n",
    "import os"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# === Neo4j Connection Setup ===\n",
    "uri = \"bolt://localhost:7687\"\n",
    "driver = GraphDatabase.driver(uri, auth=(\"neo4j\", \"123456789\"))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# === OpenAI Setup ===\n",
    "# Replace with your API key or use environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your-api-key-here\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0,\n",
    ")\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# === Milvus Setup ===\n",
    "milvus_client = MilvusClient(uri=\"./milvus.db\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# === Function to delete all existing data (optional cleanup) ===\n",
    "def delete_all_data(tx):\n",
    "    tx.run(\"MATCH (n) DETACH DELETE n\")\n",
    "    print(\"ðŸ—‘ï¸ Cleared existing data.\")\n",
    "\n",
    "# === Function to insert an entity ===\n",
    "def insert_entity(tx, name, entity_type, singular, description):\n",
    "    query = (\n",
    "        \"MERGE (e:Entity {name: $name}) \"\n",
    "        \"SET e.entity_type = $entity_type, e.singular = $singular, e.description = $description\"\n",
    "    )\n",
    "    tx.run(query, name=name, entity_type=entity_type, singular=singular, description=description)\n",
    "    print(f\"âœ… Inserted Entity: {name}\")\n",
    "\n",
    "# === Function to insert a relationship ===\n",
    "def insert_relationship(tx, entity_1, entity_2, rel_type, description):\n",
    "    query = (\n",
    "        \"MATCH (a:Entity {name: $entity_1}), (b:Entity {name: $entity_2}) \"\n",
    "        \"MERGE (a)-[r:RELATION {type: $rel_type, description: $description}]->(b)\"\n",
    "    )\n",
    "    tx.run(query, entity_1=entity_1, entity_2=entity_2, rel_type=rel_type, description=description)\n",
    "    print(f\"ðŸ”— Created Relationship: ({entity_1})-[:{rel_type}]->({entity_2})\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# === Load JSON data ===\n",
    "with open(\"/Users/shiva/Documents/Regal/data/enities_realtions.json\", \"r\") as f:\n",
    "    kg_data = json.load(f)\n",
    "\n",
    "# === Insert all entities and relationships into Neo4j ===\n",
    "with driver.session() as session:\n",
    "    # Optional: Wipe database before inserting new data\n",
    "    session.write_transaction(delete_all_data)\n",
    "\n",
    "    # Insert entities\n",
    "    for entity in kg_data[\"entities\"]:\n",
    "        session.write_transaction(\n",
    "            insert_entity,\n",
    "            entity[\"name\"],\n",
    "            entity[\"entity_type\"],\n",
    "            entity[\"singular\"],\n",
    "            entity[\"description\"]\n",
    "        )\n",
    "\n",
    "    # Insert relationships\n",
    "    for rel in kg_data[\"relationships\"]:\n",
    "        session.write_transaction(\n",
    "            insert_relationship,\n",
    "            rel[\"entity_1\"],\n",
    "            rel[\"entity_2\"],\n",
    "            rel[\"relationship_type\"],\n",
    "            rel[\"description\"]\n",
    "        )\n",
    "\n",
    "print(\"âœ… All entities and relationships inserted into Neo4j.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# === Extract triplets for Graph RAG ===\n",
    "# This function extracts triplets from the new data format\n",
    "def extract_triplets_from_new_format(kg_data):\n",
    "    triplets = []\n",
    "    triplets_with_passages = []\n",
    "    \n",
    "    # Create a mapping of entity names to their descriptions\n",
    "    entity_descriptions = {}\n",
    "    for entity in kg_data[\"entities\"]:\n",
    "        entity_descriptions[entity[\"name\"]] = entity[\"description\"]\n",
    "    \n",
    "    # Create triplets from relationships\n",
    "    for rel in kg_data[\"relationships\"]:\n",
    "        entity_1 = rel[\"entity_1\"]\n",
    "        entity_2 = rel[\"entity_2\"]\n",
    "        relationship_type = rel[\"relationship_type\"]\n",
    "        \n",
    "        # Create a triplet in the format expected by Graph RAG\n",
    "        triplet = [entity_1, relationship_type, entity_2]\n",
    "        triplets.append(triplet)\n",
    "        \n",
    "        # Create a passage from the relationship and entity descriptions\n",
    "        passage = f\"{entity_1} {relationship_type} {entity_2}. \"\n",
    "        if entity_1 in entity_descriptions:\n",
    "            passage += f\"Description of {entity_1}: {entity_descriptions[entity_1]}. \"\n",
    "        if entity_2 in entity_descriptions:\n",
    "            passage += f\"Description of {entity_2}: {entity_descriptions[entity_2]}. \"\n",
    "        if \"description\" in rel and rel[\"description\"]:\n",
    "            passage += f\"Relationship details: {rel['description']}\"\n",
    "        \n",
    "        # Store the passage with the triplet\n",
    "        triplet_with_passage = {\n",
    "            \"passage\": passage,\n",
    "            \"triplets\": [triplet]\n",
    "        }\n",
    "        triplets_with_passages.append(triplet_with_passage)\n",
    "    \n",
    "    return triplets, triplets_with_passages\n",
    "\n",
    "# Extract triplets and passages from the new data format\n",
    "triplets, triplets_with_passages = extract_triplets_from_new_format(kg_data)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# === Process triplets for Graph RAG ===\n",
    "entityid_2_relationids = defaultdict(list)\n",
    "relationid_2_passageids = defaultdict(list)\n",
    "\n",
    "entities = []\n",
    "relations = []\n",
    "passages = []\n",
    "\n",
    "# Process the triplets with passages\n",
    "for passage_id, dataset_info in enumerate(triplets_with_passages):\n",
    "    passage, triplet_list = dataset_info[\"passage\"], dataset_info[\"triplets\"]\n",
    "    passages.append(passage)\n",
    "    \n",
    "    for triplet in triplet_list:\n",
    "        if triplet[0] not in entities:\n",
    "            entities.append(triplet[0])\n",
    "        if triplet[2] not in entities:\n",
    "            entities.append(triplet[2])\n",
    "        \n",
    "        relation = \" \".join(triplet)\n",
    "        if relation not in relations:\n",
    "            relations.append(relation)\n",
    "            entityid_2_relationids[entities.index(triplet[0])].append(len(relations) - 1)\n",
    "            entityid_2_relationids[entities.index(triplet[2])].append(len(relations) - 1)\n",
    "        \n",
    "        relationid_2_passageids[relations.index(relation)].append(passage_id)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# === Create Milvus collections ===\n",
    "embedding_dim = len(embedding_model.embed_query(\"foo\"))\n",
    "\n",
    "def create_milvus_collection(collection_name: str):\n",
    "    if milvus_client.has_collection(collection_name=collection_name):\n",
    "        milvus_client.drop_collection(collection_name=collection_name)\n",
    "    milvus_client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        dimension=embedding_dim,\n",
    "        consistency_level=\"Strong\",\n",
    "    )\n",
    "\n",
    "entity_col_name = \"entity_collection\"\n",
    "relation_col_name = \"relation_collection\"\n",
    "passage_col_name = \"passage_collection\"\n",
    "create_milvus_collection(entity_col_name)\n",
    "create_milvus_collection(relation_col_name)\n",
    "create_milvus_collection(passage_col_name)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# === Insert data into Milvus ===\n",
    "def milvus_insert(\n",
    "    collection_name: str,\n",
    "    text_list: list[str],\n",
    "):\n",
    "    batch_size = 512\n",
    "    for row_id in tqdm(range(0, len(text_list), batch_size), desc=\"Inserting\"):\n",
    "        batch_texts = text_list[row_id : row_id + batch_size]\n",
    "        batch_embeddings = embedding_model.embed_documents(batch_texts)\n",
    "\n",
    "        batch_ids = [row_id + j for j in range(len(batch_texts))]\n",
    "        batch_data = [\n",
    "            {\n",
    "                \"id\": id_,\n",
    "                \"text\": text,\n",
    "                \"vector\": vector,\n",
    "            }\n",
    "            for id_, text, vector in zip(batch_ids, batch_texts, batch_embeddings)\n",
    "        ]\n",
    "        milvus_client.insert(\n",
    "            collection_name=collection_name,\n",
    "            data=batch_data,\n",
    "        )\n",
    "\n",
    "# Insert relations, entities, and passages into Milvus\n",
    "milvus_insert(\n",
    "    collection_name=relation_col_name,\n",
    "    text_list=relations,\n",
    ")\n",
    "\n",
    "milvus_insert(\n",
    "    collection_name=entity_col_name,\n",
    "    text_list=entities,\n",
    ")\n",
    "\n",
    "milvus_insert(\n",
    "    collection_name=passage_col_name,\n",
    "    text_list=passages,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# === Build adjacency matrices ===\n",
    "entity_relation_adj = np.zeros((len(entities), len(relations)))\n",
    "for entity_id, entity in enumerate(entities):\n",
    "    entity_relation_adj[entity_id, entityid_2_relationids[entity_id]] = 1\n",
    "\n",
    "entity_relation_adj = csr_matrix(entity_relation_adj)\n",
    "\n",
    "entity_adj_1_degree = entity_relation_adj @ entity_relation_adj.T\n",
    "relation_adj_1_degree = entity_relation_adj.T @ entity_relation_adj\n",
    "\n",
    "target_degree = 1\n",
    "\n",
    "entity_adj_target_degree = entity_adj_1_degree\n",
    "for _ in range(target_degree - 1):\n",
    "    entity_adj_target_degree = entity_adj_target_degree * entity_adj_1_degree\n",
    "relation_adj_target_degree = relation_adj_1_degree\n",
    "for _ in range(target_degree - 1):\n",
    "    relation_adj_target_degree = relation_adj_target_degree * relation_adj_1_degree\n",
    "\n",
    "entity_relation_adj_target_degree = entity_adj_target_degree @ entity_relation_adj"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# === Rerank relations function ===\n",
    "def rerank_relations(\n",
    "    query: str, relation_candidate_texts: list[str], relation_candidate_ids: list[str]\n",
    ") -> list[int]:\n",
    "    query_prompt_one_shot_input = \"\"\"I will provide you with a list of relationship descriptions. Your task is to select 3 relationships that may be useful to answer the given question. Please return a JSON object containing your thought process and a list of the selected relationships in order of their relevance.\n",
    "\n",
    "Question:\n",
    "When was the mother of the leader of the Third Crusade born?\n",
    "\n",
    "Relationship descriptions:\n",
    "[1] Eleanor was born in 1122.\n",
    "[2] Eleanor married King Louis VII of France.\n",
    "[3] Eleanor was the Duchess of Aquitaine.\n",
    "[4] Eleanor participated in the Second Crusade.\n",
    "[5] Eleanor had eight children.\n",
    "[6] Eleanor was married to Henry II of England.\n",
    "[7] Eleanor was the mother of Richard the Lionheart.\n",
    "[8] Richard the Lionheart was the King of England.\n",
    "[9] Henry II was the father of Richard the Lionheart.\n",
    "[10] Henry II was the King of England.\n",
    "[11] Richard the Lionheart led the Third Crusade.\n",
    "\n",
    "\"\"\"\n",
    "    query_prompt_one_shot_output = \"\"\"{'thought_process': 'To answer the question about the birth of the mother of the leader of the Third Crusade, I first need to identify who led the Third Crusade and then determine who his mother was. After identifying his mother, I can look for the relationship that mentions her birth.', 'useful_relationships': ['[11] Richard the Lionheart led the Third Crusade', '[7] Eleanor was the mother of Richard the Lionheart', '[1] Eleanor was born in 1122']}\"\"\"\n",
    "\n",
    "    query_prompt_template = \"\"\"Question:\n",
    "{question}\n",
    "\n",
    "Relationship descriptions:\n",
    "{relation_des_str}\n",
    "\n",
    "\"\"\"\n",
    "    relation_des_str = \"\\n\".join(\n",
    "        map(\n",
    "            lambda item: f\"[{item[0]}] {item[1]}\",\n",
    "            zip(relation_candidate_ids, relation_candidate_texts),\n",
    "        )\n",
    "    ).strip()\n",
    "    rerank_prompts = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            HumanMessage(query_prompt_one_shot_input),\n",
    "            AIMessage(query_prompt_one_shot_output),\n",
    "            HumanMessagePromptTemplate.from_template(query_prompt_template),\n",
    "        ]\n",
    "    )\n",
    "    rerank_chain = (\n",
    "        rerank_prompts\n",
    "        | llm.bind(response_format={\"type\": \"json_object\"})\n",
    "        | JsonOutputParser()\n",
    "    )\n",
    "    rerank_res = rerank_chain.invoke(\n",
    "        {\"question\": query, \"relation_des_str\": relation_des_str}\n",
    "    )\n",
    "    rerank_relation_ids = []\n",
    "    rerank_relation_lines = rerank_res[\"useful_relationships\"]\n",
    "    id_2_lines = {}\n",
    "    for line in rerank_relation_lines:\n",
    "        id_ = int(line[line.find(\"[\") + 1 : line.find(\"]\")])\n",
    "        id_2_lines[id_] = line.strip()\n",
    "        rerank_relation_ids.append(id_)\n",
    "    return rerank_relation_ids"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# === Example query function ===\n",
    "def query_graph_rag(query, query_ner_list=None):\n",
    "    if query_ner_list is None:\n",
    "        # Extract named entities from the query using a simple approach\n",
    "        # In a real implementation, you might use a more sophisticated NER model\n",
    "        query_ner_list = [word for word in query.split() if word[0].isupper()]\n",
    "    \n",
    "    query_ner_embeddings = [\n",
    "        embedding_model.embed_query(query_ner) for query_ner in query_ner_list\n",
    "    ]\n",
    "    \n",
    "    top_k = 3\n",
    "    \n",
    "    entity_search_res = milvus_client.search(\n",
    "        collection_name=entity_col_name,\n",
    "        data=query_ner_embeddings,\n",
    "        limit=top_k,\n",
    "        output_fields=[\"id\"],\n",
    "    )\n",
    "    \n",
    "    query_embedding = embedding_model.embed_query(query)\n",
    "    \n",
    "    relation_search_res = milvus_client.search(\n",
    "        collection_name=relation_col_name,\n",
    "        data=[query_embedding],\n",
    "        limit=top_k,\n",
    "        output_fields=[\"id\"],\n",
    "    )[0]\n",
    "    \n",
    "    expanded_relations_from_relation = set()\n",
    "    expanded_relations_from_entity = set()\n",
    "    \n",
    "    filtered_hit_relation_ids = [\n",
    "        relation_res[\"entity\"][\"id\"]\n",
    "        for relation_res in relation_search_res\n",
    "    ]\n",
    "    for hit_relation_id in filtered_hit_relation_ids:\n",
    "        expanded_relations_from_relation.update(\n",
    "            relation_adj_target_degree[hit_relation_id].nonzero()[1].tolist()\n",
    "        )\n",
    "    \n",
    "    filtered_hit_entity_ids = [\n",
    "        one_entity_res[\"entity\"][\"id\"]\n",
    "        for one_entity_search_res in entity_search_res\n",
    "        for one_entity_res in one_entity_search_res\n",
    "    ]\n",
    "    \n",
    "    for filtered_hit_entity_id in filtered_hit_entity_ids:\n",
    "        expanded_relations_from_entity.update(\n",
    "            entity_relation_adj_target_degree[filtered_hit_entity_id].nonzero()[1].tolist()\n",
    "        )\n",
    "    \n",
    "    relation_candidate_ids = list(\n",
    "        expanded_relations_from_relation | expanded_relations_from_entity\n",
    "    )\n",
    "    \n",
    "    relation_candidate_texts = [\n",
    "        relations[relation_id] for relation_id in relation_candidate_ids\n",
    "    ]\n",
    "    \n",
    "    # Rerank relations\n",
    "    rerank_relation_ids = rerank_relations(\n",
    "        query,\n",
    "        relation_candidate_texts=relation_candidate_texts,\n",
    "        relation_candidate_ids=relation_candidate_ids,\n",
    "    )\n",
    "    \n",
    "    final_top_k = 2\n",
    "    \n",
    "    final_passages = []\n",
    "    final_passage_ids = []\n",
    "    for relation_id in rerank_relation_ids:\n",
    "        for passage_id in relationid_2_passageids[relation_id]:\n",
    "            if passage_id not in final_passage_ids:\n",
    "                final_passage_ids.append(passage_id)\n",
    "                final_passages.append(passages[passage_id])\n",
    "    passages_from_our_method = final_passages[:final_top_k]\n",
    "    \n",
    "    # Compare with naive RAG\n",
    "    naive_passage_res = milvus_client.search(\n",
    "        collection_name=passage_col_name,\n",
    "        data=[query_embedding],\n",
    "        limit=final_top_k,\n",
    "        output_fields=[\"text\"],\n",
    "    )[0]\n",
    "    passages_from_naive_rag = [res[\"entity\"][\"text\"] for res in naive_passage_res]\n",
    "    \n",
    "    # Generate answers\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"human\",\n",
    "                \"\"\"Use the following pieces of retrieved context to answer the question. If there is not enough information in the retrieved context to answer the question, just say that you don't know.\n",
    "    \n",
    "    Question: {question}\n",
    "    Context: {context}\n",
    "    \n",
    "    Answer:\"\"\",\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    rag_chain = prompt | llm | StrOutputParser()\n",
    "    \n",
    "    answer_from_naive_rag = rag_chain.invoke(\n",
    "        {\"question\": query, \"context\": \"\\n\".join(passages_from_naive_rag)}\n",
    "    )\n",
    "    answer_from_our_method = rag_chain.invoke(\n",
    "        {\"question\": query, \"context\": \"\\n\".join(passages_from_our_method)}\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"passages_from_naive_rag\": passages_from_naive_rag,\n",
    "        \"passages_from_our_method\": passages_from_our_method,\n",
    "        \"answer_from_naive_rag\": answer_from_naive_rag,\n",
    "        \"answer_from_our_method\": answer_from_our_method\n",
    "    }"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# === Test the Graph RAG system ===\n",
    "test_query = \"What is the relationship between Reserve Bank and Foreign Exchange Management Act?\"\n",
    "result = query_graph_rag(test_query, [\"Reserve Bank\", \"Foreign Exchange Management Act\"])\n",
    "\n",
    "print(f\"Passages retrieved from naive RAG: \\n{result['passages_from_naive_rag']}\\n\\n\"\n",
    "      f\"Passages retrieved from our method: \\n{result['passages_from_our_method']}\\n\\n\")\n",
    "\n",
    "print(f\"Answer from naive RAG: {result['answer_from_naive_rag']}\\n\\n\"\n",
    "      f\"Answer from our method: {result['answer_from_our_method']}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Close Neo4j connection\n",
    "driver.close()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
